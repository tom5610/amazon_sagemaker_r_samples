{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R Serving with Plumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Dockerfile defines the environment in which our server will be executed.\n",
    "* Below, you can see that the entrypoint for our container will be [deploy.R](deploy.R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code: deploy.R\n",
    "\n",
    "The **deploy.R** script handles the following steps:\n",
    "* Loads the R libraries used by the server.\n",
    "* Loads a pretrained `xgboost` model that has been trained on the classical [Iris](https://archive.ics.uci.edu/ml/datasets/iris) dataset.\n",
    "  * Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "* Defines an inference function that takes a matrix of iris features and returns predictions for those iris examples.\n",
    "* Finally, it imports the [endpoints.R](endpoints.R) script and launches the Plumber server app using those endpoint definitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat deploy.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code: endpoints.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**endpoints.R** defines two routes:\n",
    "* `/ping` returns a string 'Alive' to indicate that the application is healthy\n",
    "* `/invocations` applies the previously defined inference function to the input features from the request body\n",
    "\n",
    "For more information about the requirements for building your own inference container, see:\n",
    "[Use Your Own Inference Code with Hosting Services](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat endpoints.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Serving Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  37.89kB\n",
      "Step 1/8 : FROM r-base:4.1.1\n",
      " ---> 176db8b917ff\n",
      "Step 2/8 : MAINTAINER Amazon SageMaker Examples <amazon-sagemaker-examples@amazon.com>\n",
      " ---> Using cache\n",
      " ---> 27f5aaa6d37a\n",
      "Step 3/8 : RUN apt-get -y update && apt-get install -y --no-install-recommends     wget     apt-transport-https     ca-certificates     libcurl4-openssl-dev     libsodium-dev\n",
      " ---> Using cache\n",
      " ---> 646e8a8eb34f\n",
      "Step 4/8 : RUN R -e \"install.packages(c('plumber'), repos='https://cloud.r-project.org')\"\n",
      " ---> Using cache\n",
      " ---> ad59e5a90079\n",
      "Step 5/8 : COPY endpoints.R /opt/ml/endpoints.R\n",
      " ---> 2fc412bea09f\n",
      "Step 6/8 : COPY deploy.R /opt/ml/deploy.R\n",
      " ---> edc847611640\n",
      "Step 7/8 : WORKDIR /opt/ml\n",
      " ---> Running in 43c47f7c90c2\n",
      "Removing intermediate container 43c47f7c90c2\n",
      " ---> e458fd783bb3\n",
      "Step 8/8 : ENTRYPOINT [\"/usr/bin/Rscript\", \"/opt/ml/deploy.R\", \"--no-save\"]\n",
      " ---> Running in 3e6ca1515aa5\n",
      "Removing intermediate container 3e6ca1515aa5\n",
      " ---> 06ba09c8dad6\n",
      "Successfully built 06ba09c8dad6\n",
      "Successfully tagged r-plumber:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t r-plumber ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the Serving Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Plumber\n",
      "2c16319ca2c2f7fbd833038600ee3f8a7f1630b09db8a0fd6be8515476a5d709\n",
      "docker: Error response from daemon: driver failed programming external connectivity on endpoint trusting_kilby (0aab9be97933e4767a5c65ce86ad93faf36ff070e22693348a22a4bdb979b28b): Bind for 0.0.0.0:5000 failed: port is already allocated.\n",
      "Waiting for the server to start..\n"
     ]
    }
   ],
   "source": [
    "!echo \"Launching Plumber\"\n",
    "!docker run -d --rm -p 5000:8080 r-plumber\n",
    "!echo \"Waiting for the server to start..\" && sleep 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES\n",
      "3cbe00ff2de3        0d4d7e51047e        \"/usr/bin/Rscript /oâ€¦\"   3 hours ago         Up 3 hours          0.0.0.0:5000->8080/tcp   zen_knuth\n"
     ]
    }
   ],
   "source": [
    "!docker container list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Simple Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(examples, instance=requests, port=5000):\n",
    "    payload = {\"features\": examples}\n",
    "    return instance.post(f\"http://127.0.0.1:{port}/invocations\", json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_health(instance=requests, port=5000):\n",
    "    instance.get(f\"http://127.0.0.1:{port}/ping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Example Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define example inputs from the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = get_predictions(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[5.6549]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Image to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./build_and_push.sh r-plumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please copy the uri from ECR console.\n",
    "image_name = \"r-plumber\"\n",
    "# provide proviate the account id\n",
    "account_id = ''\n",
    "r_plumber_ecr_repo_uri = \"{account_id}.dkr.ecr.ap-southeast-2.amazonaws.com/r-plumber\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and deploy on Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'my-r-model-sample-04' # must be unique\n",
    "r_model = Model(image_uri = r_plumber_ecr_repo_uri, role = role, name = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_model.deploy(initial_instance_count = 1,\n",
    "            instance_type = 'ml.m5.large'\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [3, 4]\n",
    "\n",
    "payload = str(x)\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName = 'my-r-model-sample-04-2021-09-08-02-01-06-589', # must be matched with the endpoint name\n",
    "    Body = payload,\n",
    "    ContentType='text/csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response['Body'] is stream and can only be read once\n",
    "result = response['Body'].read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('output: ', result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('input:', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop All Serving Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will shut down the serving container we launched for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker kill $(docker ps -q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
